{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13e0275-9874-46e9-8940-2f7449569d30",
   "metadata": {},
   "source": [
    "# 2.1. Fine Tune with HF Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0feba66-e33e-4813-b4ba-95fb46f5027f",
   "metadata": {},
   "source": [
    "<img src=\"imgs/finetune_pipe.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0c9f25-364c-4b5d-9533-c2ada9cb7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env CLEARML_WEB_HOST=https://app.clearml.cnasg.dellcsc.com\n",
    "#%env CLEARML_API_HOST=https://api.clearml.cnasg.dellcsc.com\n",
    "#%env CLEARML_FILES_HOST=http://files.clearml.cnasg.dellcsc.com\n",
    "# llm-workshop\n",
    "#%env CLEARML_API_ACCESS_KEY=N3PGHCVPJ05SG9CXLO7X\n",
    "#%env CLEARML_API_SECRET_KEY=z3EPKoHoY34q7GV9pmGIbF50WPdGIuXt0RNMQkFI6Fri1BRlwt\n",
    "#%env CLEARML_LOG_MODEL=True\n",
    "#%env CLEARML_VERIFY_CERTIFICATE=False\n",
    "#%env CLEARML_CONFIG_FILE=\"/home/cnasg/codes/yx/clearml.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191469f4-77e2-4a48-8a0e-a9791bd836f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=42e7b5e19310468aa87f6ffe3096d69e\n",
      "ClearML results page: http://app.clearml.cnasg.dellcsc.com/projects/63dc34ec6ac84dcdbc76686666020119/experiments/42e7b5e19310468aa87f6ffe3096d69e/output/log\n",
      "2024-05-11 13:39:34,381 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: http://app.clearml.cnasg.dellcsc.com/projects/63dc34ec6ac84dcdbc76686666020119/experiments/42e7b5e19310468aa87f6ffe3096d69e/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "#!pip install -r requirements.txt\n",
    "#!pip install clearml\n",
    "#!pip install nbconvert \n",
    "from clearml import Task\n",
    "task = Task.init(project_name='stk', task_name='fine-tune-llm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fade31b",
   "metadata": {},
   "source": [
    "### Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7431195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d73e5-47d8-446b-accc-bcd6f179063c",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model\n",
    "In order to fine-tune a model, we have to start off with the pre-trained model itself, and apply some configurations to prepare it for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d4b6dc-8565-4717-881c-979f470d6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model from huggingface\n",
    "base_model_name = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "\n",
    "# Fine-tuned model\n",
    "new_model = \"./results/tinyllama-medical\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b07f0-3e30-41c7-bba6-5cf81d4b1c6a",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a169b-e460-42b9-856d-1244450e59b9",
   "metadata": {},
   "source": [
    "*In the context of natural language processing and machine learning, **pad_token_id** typically refers to the identifier or index assigned to a special token representing padding in a sequence. When working with sequences of varying lengths, it's common to pad shorter sequences with a special token to make them uniform in length.*\n",
    "\n",
    "Eg:\n",
    "```\n",
    "data = [ \"I like cat\", \"Do you like cat too?\"]\n",
    "tokenizer(data, padding=True, truncation=True, return_tensors='pt')\n",
    "```\n",
    "Output:\n",
    "```\n",
    "'input_ids': tensor([[101,146,1176,5855,102,0,0,0],[101,2091,1128,1176,5855,1315,136,102]])\n",
    "'token_type_ids': tensor([[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]])\n",
    "'attention_mask': tensor([[1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f825a153-80a1-41ae-b44f-083721206e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a778cd97-0362-432c-9cf2-a32f67214224",
   "metadata": {},
   "source": [
    "## Load Dataset from ðŸ¤—HuggingFace\n",
    "\n",
    "Hugging Face Datasets is designed to simplify the process of working with and accessing various datasets commonly used in NLP tasks. The library offers a collection of datasets for tasks such as text classification, named entity recognition, question answering, and more. [link](https://huggingface.co/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd6b6a3-3f5c-4dd3-8c59-e08bdc02f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New instruction dataset\n",
    "data = load_dataset(\"BI55/MedText\", split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998e8c33-5cfb-43b7-8e55-e71d4622aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(dataset):\n",
    "    dataset['Prompt'] = ' '.join(dataset['Prompt'].split())\n",
    "    dataset['Completion'] = ' '.join(dataset['Completion'].split())\n",
    "\n",
    "    full_prompt = f\"<s>[INST] {dataset['Prompt']} [/INST] {dataset['Completion']} </s>\"\n",
    "    result = {}\n",
    "    result['text'] = full_prompt\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8d0104-2d42-49f9-943f-b280c656423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1412\n",
      "})\n",
      "<s>[INST] A 55-year-old female presents with new onset seizures. She has a history of sinusitis which was treated with a course of antibiotics by her primary care doctor a month ago. She also reports an intermittent headache over the past few weeks. CT scan reveals a cerebral abscess. What could be the cause? [/INST] The cerebral abscess in this patient is likely a complication from the recent sinusitis, which may not have been fully resolved with the course of antibiotics. Sinus infections can occasionally spread to the brain if not adequately treated. This patient will require hospitalization, IV antibiotics, and likely neurosurgical consultation for possible drainage of the abscess. </s>\n"
     ]
    }
   ],
   "source": [
    "formatted_dataset = data.map(prompt_formatter, remove_columns=['Prompt', 'Completion'])\n",
    "print(formatted_dataset)\n",
    "print(formatted_dataset[50]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5ecf6-1954-4d4b-b441-9fb9f6cb2047",
   "metadata": {},
   "source": [
    "## Prepare Model for Q-Lora INT4 Fine Tuning\n",
    "\n",
    "<img src=\"imgs/qlora.png\" width=\"800\"/>\n",
    "\n",
    "[Reference](https://www.linkedin.com/pulse/trends-llms-qlora-efficient-finetuning-quantized-vijay/?trk=article-ssr-frontend-pulse_more-articles_related-content-card)\n",
    "\n",
    "Summary:\n",
    "1. 4-bit quantization of the full pretrained language model to compress weights and reduce memory requirements using a novel NormalFloat encoding optimized for the distribution of neural network weights.\n",
    "2. Low-rank adapters added densely throughout the layers of the 4-bit quantized base model. The adapters use full 16-bit precision and are finetuned while the base model remains fixed.\n",
    "3. Double quantization further reduces memory by quantizing the first-stage quantization constants themselves from 32-bit to 8-bit with no accuracy loss.\n",
    "4. Paged optimizers leverage unified memory to gracefully handle gradient checkpointing memory spikes and finetune models larger than the physical GPU memory through automatic paging.\n",
    "5. Mixed precision combines 4-bit weights with 16-bit adapter parameters and activations, maximizing memory savings while retaining accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93802cf-b4c9-4e7c-b367-375d4b9bb78e",
   "metadata": {},
   "source": [
    "### LoRA Configuration\n",
    "\n",
    "LoraConfig allows you to control how LoRA is applied to the base model through the following parameters:\n",
    "\n",
    "***target_modules** - The modules (for example, attention blocks) to apply the LoRA update matrices* [Reference](https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms) - By default, all linear modules are targted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8e126d-6f28-4f46-8d35-a52c1dca44d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185a344f-3c94-4fb1-86bd-3de6b2484c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1126400 || all params: 616732672 || trainable%: 0.1826399104732366\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_args = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_args)\n",
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2495e8-ed62-4d82-8953-31b42cfd7fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_steps=100,\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=300,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=formatted_dataset,\n",
    "    peft_config=peft_args,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd730949-e701-4fd8-988e-6210bbb453a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switching to remote execution, output log page http://app.clearml.cnasg.dellcsc.com/projects/63dc34ec6ac84dcdbc76686666020119/experiments/42e7b5e19310468aa87f6ffe3096d69e/output/log\n"
     ]
    }
   ],
   "source": [
    "task.execute_remotely(queue_name=\"qw1\")\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71886b4c-2237-4ce5-b73c-f1c6e6e877ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_adapter = \"./results/tinyllama-medical-adapter\"\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model_adapter)\n",
    "trainer.tokenizer.save_pretrained(new_model_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85e918-7763-4a2a-a2c7-01fc0b3b5a4d",
   "metadata": {},
   "source": [
    "## Merging LoRa adapter weights into the base pre-trained model\n",
    "Now that we have successfully fine-tuned the model using LoRa, the next step is to merge the adapter weights into the original pre-trained model.\n",
    "We will be going through the steps in the next notebook. Before that, please restart or kill this current runtime to release the used memory from the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda816f-d811-4485-852b-1edd8a1db64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68214d29-a033-4d96-9daa-8d3576979964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
